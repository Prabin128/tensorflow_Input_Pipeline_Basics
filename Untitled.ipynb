{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "719c8f57",
   "metadata": {},
   "source": [
    "# TF Data Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3d8c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb9fd51",
   "metadata": {},
   "source": [
    "# Creating tf dataset from a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75c12258",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales_numbers = [21, 22,-108, 31, -1, 32, 34, 31]   #daily sales cant be negative so, these are all the data errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd7e406",
   "metadata": {},
   "source": [
    "#### we want to build a tf dataset from the above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42cc310d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1029fed7",
   "metadata": {},
   "source": [
    "### Iterating through elements as numpy elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64d35171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)\n",
    "    \n",
    "    ##next method that gives same result\n",
    "# for sales in tf_dataset:\n",
    "#     print(sales)    \n",
    "    \n",
    "## here, individual element is tenser So, to convert "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a911c96",
   "metadata": {},
   "source": [
    "### in above output, individual element is tenser So, if we wanted to convert in Numpy object  then using a Numpy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3849a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset:\n",
    "    print(sales.numpy()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e334e86",
   "metadata": {},
   "source": [
    "## Filtering sales numbers that are less than 0 \n",
    "##### sales number cant be - so filtering those data points .. By using filter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09d550fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "31\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.filter(lambda x: x>0)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84d195d",
   "metadata": {},
   "source": [
    "### the above code is giving the warning  as :  Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. \n",
    "### so it may not be useful in the future so the below mentioned code is the updated version of the above code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "032e9190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "31\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# Define a lambda function to filter the dataset\n",
    "def filter_fn(x):\n",
    "    return x > 0\n",
    "\n",
    "# Filter the dataset using the filter() method\n",
    "tf_dataset = tf_dataset.filter(filter_fn)\n",
    "\n",
    "# Iterate over the filtered dataset\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cf1220",
   "metadata": {},
   "source": [
    "## suppose the above sales are in dollar so we wanna convert it in nepali currenncy\n",
    "### we use map function => it will take each individual element & it will apply that particular function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "170063c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2520\n",
      "2640\n",
      "3720\n",
      "3840\n",
      "4080\n",
      "3720\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.map(lambda x: x*120)  #x is the individual element so we convert here for all the elements\n",
    "for sales in tf_dataset:\n",
    "    print(sales.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70a81da",
   "metadata": {},
   "source": [
    "## Shuffling the datas\n",
    "### we may want to randomly shuffle the datas especially when we are doing image data analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ca36a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2520\n",
      "2640\n",
      "3840\n",
      "4080\n",
      "3720\n",
      "3720\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.shuffle(2) #buffer of size 2\n",
    "for sales in tf_dataset:\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9bb7a2",
   "metadata": {},
   "source": [
    "<h1>Batching </h1>\n",
    "\n",
    "<h3>Lots of images are stored on harddisk so we cannot processs all those images at once so we need to process those images in the form of batch \n",
    "</h3>\n",
    "\n",
    "<h4>df.batch(n)   ,  n => no of batches you want to create</h4>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f69480a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2520 2640]\n",
      "[3840 4080]\n",
      "[3720 3720]\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.batch(2):\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d95ecd0",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> Forming all of the above code in a single line </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ea405b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[446400 460800]\n",
      "[316800 489600]\n",
      "[302400 446400]\n"
     ]
    }
   ],
   "source": [
    "tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "tf_dataset = tf_dataset.filter(lambda x: x>0).map(lambda y: y *120).shuffle(2).batch(2)\n",
    "for sales in tf_dataset:\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b1a859",
   "metadata": {},
   "source": [
    "# reading cat and dog images from the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29f6be9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'E:\\\\python\\\\images\\\\cat\\\\image1.jpeg'\n",
      "b'E:\\\\python\\\\images\\\\cat\\\\image11.jpg'\n",
      "b'E:\\\\python\\\\images\\\\cat\\\\image12.jpg'\n",
      "b'E:\\\\python\\\\images\\\\cat\\\\image22.jpg'\n",
      "b'E:\\\\python\\\\images\\\\cat\\\\image23.jpg'\n"
     ]
    }
   ],
   "source": [
    "images_ds = tf.data.Dataset.list_files('E:\\python/images/*/*', shuffle = False)\n",
    "for file in images_ds.take(5):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "499188e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'E:\\\\python\\\\images\\\\dog\\\\dog77.jpg'\n",
      "b'E:\\\\python\\\\images\\\\cat\\\\image11.jpg'\n",
      "b'E:\\\\python\\\\images\\\\cat\\\\images9.jpeg'\n"
     ]
    }
   ],
   "source": [
    "# by shuffling the above code\n",
    "images_ds = images_ds.shuffle(200)\n",
    "for file in images_ds.take(3):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "993ec71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"cat\", \"dog\"] # class names hami sanga cat rw dog xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4063dce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = len(images_ds)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5bb00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(image_count*0.8) # lets say trainning size is 0.8, 80% of my sample are of training size \n",
    "\n",
    "train_ds = images_ds.take(train_size) ## take function will take first 80% of images as datasets\n",
    "test_ds = images_ds.skip(train_size)  # skip is opposite of take, skip will skip the first 80% of th images of dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ff3c2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b3e0622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds)  ##So total ma 40 ota thyo, take le 32  ota images ligyo and test le remaining "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b129dabb",
   "metadata": {},
   "source": [
    "# from images path we need to retrive the lable  (path stringma xa we retrive label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f8aefbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example\n",
    "s = 'E:\\\\python\\\\images\\\\dog\\\\images.jfif'\n",
    "s.split(\"\\\\\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "03546527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    import os\n",
    "    return tf.strings.split(file_path, os.path.sep)[-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b17a4850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'E:\\\\python\\\\images\\\\cat\\\\images5.jfif'\n",
      "b'E:\\\\python\\\\images\\\\dog\\\\dog77.jpg'\n",
      "b'E:\\\\python\\\\images\\\\dog\\\\dog55.jpg'\n",
      "b'E:\\\\python\\\\images\\\\cat\\\\images6.jfif'\n",
      "b'E:\\\\python\\\\images\\\\cat\\\\images7.jfif'\n"
     ]
    }
   ],
   "source": [
    "## first lets see what we have in the train_ds :\n",
    "\n",
    "for t in train_ds.take(5): #take(5) is just like a .head() in the pandas , it takes only 5 items present in the datasets\n",
    "    print(t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "833a189b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    " #map function will apply get_label function to all the elements in train_ds\n",
    "for label in train_ds.map(get_label):\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136bbe7b",
   "metadata": {},
   "source": [
    "# From the above output we only got cat and dog (i.e our y part)\n",
    "\n",
    "## X train in the below image is our actual image data .. and y train is our cat and dog(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b039220",
   "metadata": {},
   "source": [
    "<img src=\"image.png\" style=\"height:50%, width:50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab534a50",
   "metadata": {},
   "source": [
    "## Now, We are gonna get the x part i.e our actual image data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7b9b494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(file_path):\n",
    "    label = get_label(file_path) \n",
    "    \n",
    "    img = tf.io.read_file(file_path)  # in tensorflow , this will read the file path\n",
    "    #our file is a jfif image, we need to decode the image\n",
    "    img= tf.image.decode_jpeg(img)\n",
    "    #our images are of different dimension we should resize \n",
    "    img = tf.image.resize(img, [128,128])\n",
    "    \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c60b87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image : tf.Tensor(\n",
      "[[[167.91156   142.91156   135.91156  ]\n",
      "  [172.        147.        140.       ]\n",
      "  [174.64453   151.64453   143.64453  ]\n",
      "  ...\n",
      "  [ 13.805481   11.899231   17.805481 ]\n",
      "  [ 14.328125   13.328125   18.328125 ]\n",
      "  [ 18.389221   16.389221   21.389221 ]]\n",
      "\n",
      " [[169.51141   144.51141   137.51141  ]\n",
      "  [173.3858    148.3858    141.3858   ]\n",
      "  [176.45312   153.45312   145.45312  ]\n",
      "  ...\n",
      "  [ 15.338318   13.432068   19.338318 ]\n",
      "  [ 14.328125   13.328125   18.328125 ]\n",
      "  [ 20.109375   18.109375   23.109375 ]]\n",
      "\n",
      " [[172.76642   147.76642   140.76642  ]\n",
      "  [176.55707   151.55707   144.55707  ]\n",
      "  [178.36719   155.36719   147.36719  ]\n",
      "  ...\n",
      "  [ 19.62854    15.897949   23.972473 ]\n",
      "  [ 17.82727    15.870239   20.87024  ]\n",
      "  [ 20.152344   18.152344   23.152344 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[179.        150.        142.       ]\n",
      "  [179.        150.        142.       ]\n",
      "  [179.        150.        142.       ]\n",
      "  ...\n",
      "  [ 36.372314   30.614685   32.684937 ]\n",
      "  [ 73.33594    51.881287   53.50934  ]\n",
      "  [126.282166   83.84076    60.483704 ]]\n",
      "\n",
      " [[180.        151.        143.       ]\n",
      "  [180.        151.        143.       ]\n",
      "  [180.        151.        143.       ]\n",
      "  ...\n",
      "  [  8.124512    7.451111    9.463684 ]\n",
      "  [ 27.173523   24.548523   23.318054 ]\n",
      "  [ 54.661377   39.853394   37.81012  ]]\n",
      "\n",
      " [[181.        152.        144.       ]\n",
      "  [181.        152.        144.       ]\n",
      "  [181.        152.        144.       ]\n",
      "  ...\n",
      "  [ 10.505493    5.9804688  10.703918 ]\n",
      "  [ 11.538147    9.538147   11.881897 ]\n",
      "  [ 17.703308   17.047058   17.442688 ]]], shape=(128, 128, 3), dtype=float32)\n",
      "label : tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "Image : tf.Tensor(\n",
      "[[[180.         185.         188.        ]\n",
      "  [182.         187.         190.        ]\n",
      "  [182.         187.         190.        ]\n",
      "  ...\n",
      "  [145.90625    155.         157.45312   ]\n",
      "  [144.         154.         156.        ]\n",
      "  [143.         153.         155.        ]]\n",
      "\n",
      " [[180.         185.         188.        ]\n",
      "  [182.         187.         190.        ]\n",
      "  [182.         187.         190.        ]\n",
      "  ...\n",
      "  [145.90625    155.         157.45312   ]\n",
      "  [144.         154.         156.        ]\n",
      "  [143.         153.         155.        ]]\n",
      "\n",
      " [[180.9375     185.9375     188.9375    ]\n",
      "  [182.         187.         190.        ]\n",
      "  [182.         187.         190.        ]\n",
      "  ...\n",
      "  [146.6753     155.25635    157.75342   ]\n",
      "  [144.9375     154.         156.46875   ]\n",
      "  [143.         153.         155.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[140.         136.9375     138.875     ]\n",
      "  [140.         136.9375     138.875     ]\n",
      "  [140.46875    137.40625    138.40625   ]\n",
      "  ...\n",
      "  [ 15.743652     1.7436523    0.74365234]\n",
      "  [ 15.53125      1.53125      0.53125   ]\n",
      "  [ 15.53125      1.53125      0.53125   ]]\n",
      "\n",
      " [[139.         135.         136.        ]\n",
      "  [139.         135.         136.        ]\n",
      "  [139.         135.         136.        ]\n",
      "  ...\n",
      "  [ 16.           2.           1.        ]\n",
      "  [ 16.           2.           1.        ]\n",
      "  [ 16.           2.           1.        ]]\n",
      "\n",
      " [[136.09375    132.09375    133.09375   ]\n",
      "  [136.09375    132.09375    133.09375   ]\n",
      "  [136.09375    132.09375    133.09375   ]\n",
      "  ...\n",
      "  [ 16.           2.           1.        ]\n",
      "  [ 16.           2.           1.        ]\n",
      "  [ 16.           2.           1.        ]]], shape=(128, 128, 3), dtype=float32)\n",
      "label : tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "Image : tf.Tensor(\n",
      "[[[226.63281  179.63281  111.63281 ]\n",
      "  [226.89844  181.89844  114.89844 ]\n",
      "  [229.       184.16406  119.49219 ]\n",
      "  ...\n",
      "  [113.15021  102.15021   83.88104 ]\n",
      "  [110.23956   99.22131   81.25781 ]\n",
      "  [108.17969   96.17969   82.17969 ]]\n",
      "\n",
      " [[226.63281  179.63281  111.63281 ]\n",
      "  [226.89844  181.89844  114.89844 ]\n",
      "  [229.       184.16406  119.49219 ]\n",
      "  ...\n",
      "  [114.82562  103.28656   86.364685]\n",
      "  [112.92975  101.34387   84.62512 ]\n",
      "  [111.15625   99.15625   85.552124]]\n",
      "\n",
      " [[226.63281  179.63281  111.63281 ]\n",
      "  [226.89844  181.89844  114.89844 ]\n",
      "  [229.       184.16406  119.49219 ]\n",
      "  ...\n",
      "  [117.46875  105.46875   91.265625]\n",
      "  [116.59375  104.59375   90.59375 ]\n",
      "  [119.28906  107.28906   95.16052 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[197.48541  178.48541  146.48541 ]\n",
      "  [192.59534  176.59534  143.59534 ]\n",
      "  [191.09998  174.41144  144.79529 ]\n",
      "  ...\n",
      "  [ 94.33801   83.33801   53.338013]\n",
      "  [ 91.90875   80.90875   50.908752]\n",
      "  [ 92.30469   80.30469   54.304688]]\n",
      "\n",
      " [[199.4477   181.8305   149.36957 ]\n",
      "  [185.51526  169.05432  137.43713 ]\n",
      "  [204.64215  188.57684  160.51965 ]\n",
      "  ...\n",
      "  [ 99.55719   88.55719   58.55719 ]\n",
      "  [ 96.70294   85.70294   55.70294 ]\n",
      "  [ 98.22656   86.22656   60.226562]]\n",
      "\n",
      " [[207.85773  191.85773  158.85773 ]\n",
      "  [225.02118  208.02118  178.02118 ]\n",
      "  [219.47736  204.3133   175.80548 ]\n",
      "  ...\n",
      "  [105.579895  94.579895  64.579895]\n",
      "  [105.10675   94.10675   64.10675 ]\n",
      "  [107.74219   95.74219   69.74219 ]]], shape=(128, 128, 3), dtype=float32)\n",
      "label : tf.Tensor(b'cat', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(process_image)\n",
    "for image, label in train_ds.take(3):\n",
    "    print(\"Image :\", image)\n",
    "    print(\"label :\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f1715",
   "metadata": {},
   "source": [
    "## We got the numpy array in above output so we need to scale it \n",
    "\n",
    " we need to convert those numbers in the range of 0,1 so thats why we are scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c70137f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    return image/255, label   #RGB values are between 0 to 255 so we scaled in 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8f1cf9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image : [1.5378702e-05 1.5324988e-05 1.5083753e-05]\n",
      "label : b'dog'\n",
      "Image : [8.3225914e-06 1.3509133e-05 1.5016849e-05]\n",
      "label : b'dog'\n",
      "Image : [1.5378702e-05 1.5378702e-05 1.5378702e-05]\n",
      "label : b'dog'\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(scale)\n",
    "for image, label in train_ds.take(3):\n",
    "    print(\"Image :\", image.numpy()[0][0]) # we didnt printed the entrire image, we just printed first few elements\n",
    "    print(\"label :\", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dfeed0",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d5137",
   "metadata": {},
   "source": [
    "Movie reviews are present as individual text file (one file per review) in review folder.\n",
    "\n",
    "\n",
    "Folder structure looks like this,\n",
    "\n",
    "                        reviews\n",
    "                            |__ positive\n",
    "                                |__pos_1.txt\n",
    "                                |__pos_2.txt\n",
    "                                |__pos_3.txt\n",
    "                            |__ negative\n",
    "                                |__neg_1.txt\n",
    "                                |__neg_2.txt\n",
    "                                |__neg_3.txt\n",
    "                                \n",
    "                                \n",
    "You need to read these reviews using tf.data.Dataset and perform following transformations,\n",
    "\n",
    "    1. Read text review and generate a label from folder name.Your dataset should have review text and label as a tuple\n",
    "    2. Filter blank text review. Two files are blank in this dataset\n",
    "    3. Do all of the above transformations in single line of code. Also shuffle all the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "06955791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efab6a2",
   "metadata": {},
   "source": [
    "## Now we gonna retrive those file paths in a tf dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "57ab716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tf.data.Dataset.list_files('Exercise/reviews/*/*', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bd789119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Exercise\\\\reviews\\\\negative\\\\neg_1.txt'\n",
      "b'Exercise\\\\reviews\\\\negative\\\\neg_2.txt'\n",
      "b'Exercise\\\\reviews\\\\negative\\\\neg_3.txt'\n",
      "b'Exercise\\\\reviews\\\\positive\\\\pos_1.txt'\n",
      "b'Exercise\\\\reviews\\\\positive\\\\pos_2.txt'\n",
      "b'Exercise\\\\reviews\\\\positive\\\\pos_3.txt'\n"
     ]
    }
   ],
   "source": [
    "for items in df:\n",
    "    print(items.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e94671",
   "metadata": {},
   "source": [
    "### 1. Read text review and generate a label from folder name.Your dataset should have review text and label as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "38abfc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "def review_label(file_path):\n",
    "    return tf.io.read_file(file_path), tf.strings.split(file_path, os.path.sep)[-2]   \n",
    "#tf.io.read_file(file_path) = reads the contents of the file at the given file_path location \n",
    "                              # and returns the content as a string tensor. \n",
    "# tf.strings.split(file_path,os.path.sep)[-2] => splits the file_path string using the path separator (os.path.sep) and \n",
    "                                           # returns the second-to-last element of the resulting split string as a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7aad1a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW :  b\"Basically there's a family where a little boy (Jak\"\n",
      "LABEL :  b'negative'\n",
      "REVIEW :  b'This show was an amazing, fresh & innovative idea '\n",
      "LABEL :  b'negative'\n",
      "REVIEW :  b''\n",
      "LABEL :  b'negative'\n",
      "REVIEW :  b'One of the other reviewers has mentioned that afte'\n",
      "LABEL :  b'positive'\n",
      "REVIEW :  b'A wonderful little production. <br /><br />The fil'\n",
      "LABEL :  b'positive'\n",
      "REVIEW :  b''\n",
      "LABEL :  b'positive'\n"
     ]
    }
   ],
   "source": [
    "mapped_review = df.map(review_label)\n",
    "#since the question is asking that we should have review text and label so \n",
    "for review, label in mapped_review:\n",
    "    print(\"REVIEW : \" , review.numpy()[:50])\n",
    "    print(\"LABEL : \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39289f00",
   "metadata": {},
   "source": [
    "### 2. Filter blank text review. Two files are blank in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5112c640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW :  b\"Basically there's a family where a little boy (Jak\"\n",
      "LABEL :  b'negative'\n",
      "REVIEW :  b'This show was an amazing, fresh & innovative idea '\n",
      "LABEL :  b'negative'\n",
      "REVIEW :  b'One of the other reviewers has mentioned that afte'\n",
      "LABEL :  b'positive'\n",
      "REVIEW :  b'A wonderful little production. <br /><br />The fil'\n",
      "LABEL :  b'positive'\n"
     ]
    }
   ],
   "source": [
    "# Define a lambda function to filter the review\n",
    "def filter_df(label):\n",
    "    return label\n",
    "filtered_review = mapped_review.filter(lambda review, label : review!= \"\") #to remove any reviews with empty text \n",
    "for review, label in filtered_review:\n",
    "    print(\"REVIEW : \" , review.numpy()[:50])\n",
    "    print(\"LABEL : \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24131e90",
   "metadata": {},
   "source": [
    "### 3. Do all of the above transformations in single line of code. Also shuffle all the review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4baa17",
   "metadata": {},
   "source": [
    "<h3 style =\"color: red\"> Performing map, filter and shuffle all in single line of code</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "95598330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b\"Basically there's a family where a little boy (Jak\"\n",
      "Label: b'negative'\n",
      "Review: b'A wonderful little production. <br /><br />The fil'\n",
      "Label: b'positive'\n",
      "Review: b'One of the other reviewers has mentioned that afte'\n",
      "Label: b'positive'\n",
      "Review: b'This show was an amazing, fresh & innovative idea '\n",
      "Label: b'negative'\n"
     ]
    }
   ],
   "source": [
    "final_transformation_ds = df.map(review_label).filter(lambda review, label : review != \"\").shuffle(3)\n",
    "for review, label in final_transformation_ds.as_numpy_iterator():\n",
    "    print(\"Review:\",review[:50])\n",
    "    print(\"Label:\",label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
